{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "([2.87146875, 1.2518552564125824], [0.28155468750000001, 0.13990712578426748])\n",
      "(2000, 200) (2000, 8, 8, 200)\n",
      "(2000, 512) (2000, 200) (2000, 200)\n",
      "(2000, 200) (2000, 8, 8, 200)\n",
      "771 743 1999\n",
      "(4000, 8, 8, 200)\n",
      "(2742, 8, 8, 200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import json\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "from utils import *\n",
    "\n",
    "file_path = '/export/home/qliu24/VC_adv_data/feng/'\n",
    "vc = 0\n",
    "fake_dic = json.load(open(file_path+ 'feng_vc' + str(vc) + '_fake', 'r'))\n",
    "# real_dic = json.load(open(file_path+ 'vc' + str(vc) + 'real', 'r'))\n",
    "fake_code4 = np.array(fake_dic['fake_code4'])\n",
    "# fake_code4[vc,vc] = False\n",
    "fake_code3 = np.array(fake_dic['fake_code3'])\n",
    "\n",
    "# real_code4 = np.array(real_dic['real_code4'])\n",
    "# real_code3 = np.array(real_dic['real_code3'])[real_code4[:,vc]]\n",
    "# real_code3 = np.array(real_dic['real_code3'])\n",
    "\n",
    "# fake_code3 = np.delete(fake_code3, (vc, ), axis=0)\n",
    "print(vc)\n",
    "# print(get_stats(real_code3))\n",
    "print(get_stats(fake_code3))\n",
    "\n",
    "ori_dic = json.load(open(file_path+ 'feng_vc' + str(vc) + '_fake_ori', 'r'))\n",
    "ori4 = np.array(ori_dic['ori4'])\n",
    "ori_dis4 = np.array(ori_dic['ori_dis4'])\n",
    "ori_code4 = np.array(ori_dic['ori_code4'])\n",
    "\n",
    "real_dic = json.load(open(file_path+ 'vc' + str(vc) + '_real', 'r'))\n",
    "real_code4 = np.array(real_dic['real_code4'])\n",
    "real_code3 = np.array(real_dic['real_code3'])\n",
    "\n",
    "print(fake_code4.shape, fake_code3.shape)\n",
    "print(ori4.shape, ori_dis4.shape, ori_code4.shape)\n",
    "print(real_code4.shape, real_code3.shape)\n",
    "msk_fake = np.logical_and(np.logical_not(ori_code4[:,vc]), fake_code4[:,vc])\n",
    "print(np.sum(fake_code4[:,vc]), np.sum(msk_fake), np.sum(real_code4[:,vc]))\n",
    "msk_real = real_code4[:,vc]\n",
    "msk = np.concatenate([msk_fake, msk_real], axis=0)\n",
    "concat = np.concatenate((fake_code3, real_code3), axis=0)\n",
    "print(concat.shape)\n",
    "concat = concat[msk]\n",
    "print(concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2742, 2742)\n"
     ]
    }
   ],
   "source": [
    "fname = file_path + 'simmat_vc{}.pickle'.format(vc)\n",
    "with open(fname, 'rb') as fh:\n",
    "    mat1, mat2 = pickle.load(fh)\n",
    "    \n",
    "mat = mat1\n",
    "print(mat.shape)\n",
    "N = mat.shape[0]\n",
    "mat_full = mat + mat.T - np.ones((N,N))\n",
    "np.fill_diagonal(mat_full, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9323308270676691,0.7950036737692872,0.7281292059219381\n"
     ]
    }
   ],
   "source": [
    "N_f = np.sum(msk_fake)\n",
    "N_r = np.sum(msk_real)\n",
    "label1 = np.concatenate((np.zeros((N_f, )), np.ones((N_r, ))), axis=0)\n",
    "label2 = np.concatenate((np.ones((N_f, )), np.zeros((N_r, ))), axis=0)\n",
    "\n",
    "kk=5\n",
    "predict1 = knn_cls_no_neg(kk, mat_full, N_f, N_r, 1, coef_std=2)\n",
    "predict2 = knn_cls_no_neg(kk, mat_full, N_f, N_r, 0, coef_std=2)\n",
    "print(\"{0},{1},{2}\".format(f1_score(label1, predict1), f1_score(label2, predict2), np.sum(label1[0:N_f] == predict1[0:N_f])/N_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxGMHE/GBXP4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e9f417828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ori_dis_vc = ori_dis4[:,vc][msk_fake]\n",
    "plt.hist(ori_dis_vc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60377572629 0.677971334576 0.754246406753\n",
      "0.9586034912718204,0.5388888888888889,0.521505376344086\n",
      "0.964133433659393,0.6246719160104987,0.6432432432432432\n",
      "0.9711975745325923,0.7233009708737863,0.8010752688172043\n",
      "0.9778682269142712,0.8018223234624146,0.946236559139785\n"
     ]
    }
   ],
   "source": [
    "pctl0 = 0\n",
    "pctl1 = np.percentile(ori_dis_vc, 25)\n",
    "pctl2 = np.percentile(ori_dis_vc, 50)\n",
    "pctl3 = np.percentile(ori_dis_vc, 75)\n",
    "pctl4 = 1.0\n",
    "print(pctl1, pctl2, pctl3)\n",
    "\n",
    "# pctl1= 0.55\n",
    "# pctl2 = 0.65\n",
    "# pctl3 = 0.75\n",
    "\n",
    "pctl_ls = [pctl0, pctl1, pctl2, pctl3, pctl4]\n",
    "for p1,p2 in zip(pctl_ls[0:-1], pctl_ls[1:]):\n",
    "    msk_pctl = np.logical_and(ori_dis_vc>=p1, ori_dis_vc<p2)\n",
    "    N_f2 = np.sum(msk_pctl)\n",
    "    msk_concat = np.concatenate([msk_pctl, np.ones(N_r).astype(bool)], axis=0)\n",
    "    label1_pctl = label1[msk_concat]\n",
    "    label2_pctl = label2[msk_concat]\n",
    "    mat_full_pctl = mat_full[msk_concat][:,msk_concat]\n",
    "    kk=5\n",
    "    predict1 = knn_cls_no_neg(kk, mat_full_pctl, N_f2, N_r, 1, coef_std=2)\n",
    "    predict2 = knn_cls_no_neg(kk, mat_full_pctl, N_f2, N_r, 0, coef_std=2)\n",
    "    print(\"{0},{1},{2}\".format(f1_score(label1_pctl, predict1), f1_score(label2_pctl, predict2), np.sum(label1_pctl[0:N_f2] == predict1[0:N_f2])/N_f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2207, 6, 6, 223) (2207,)\n"
     ]
    }
   ],
   "source": [
    "# fake_code3 = fake_code3.reshape((fake_code3.shape[0], -1), order='F')\n",
    "# real_code3 = real_code3.reshape((real_code3.shape[0], -1), order='F')\n",
    "\n",
    "concat = np.concatenate((fake_code3, real_code3), axis=0)\n",
    "label = np.concatenate((np.zeros((fake_code3.shape[0], )), np.ones((real_code3.shape[0], ))), axis=0)\n",
    "\n",
    "print(concat.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'centers'])\n"
     ]
    }
   ],
   "source": [
    "mat_contents = sio.loadmat('/export/home/qliu24/qing_voting_139/qing_voting_py/intermediate/dictionary/dictionary_imagenet_car_vgg16_pool4_K176_norm_nowarp_prune_512.mat')\n",
    "centers = np.array(mat_contents['centers']).T\n",
    "c_dist = cdist(real_code4, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = 0\n",
    "fake_dic = json.load(open(file_path+ 'vc' + str(vc) + 'fake', 'r'))\n",
    "real_dic = json.load(open(file_path+ 'vc' + str(vc) + 'real', 'r'))\n",
    "real_code4 = np.array(real_dic['real_code4'])\n",
    "real_code4[2742, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 44\n",
      "1\n",
      "1 48\n",
      "2\n",
      "2 65\n",
      "3\n",
      "3 50\n",
      "4\n",
      "4 64\n"
     ]
    }
   ],
   "source": [
    "file_path = '/export/home/qliu24/VC_adv_data/'\n",
    "for vc in range(5):\n",
    "    print(vc)\n",
    "    fake_dic = json.load(open(file_path+ 'vc' + str(vc) + 'fake', 'r'))\n",
    "    real_dic = json.load(open(file_path+ 'vc' + str(vc) + 'real', 'r'))\n",
    "\n",
    "    real_code4 = np.array(real_dic['real_code4'])\n",
    "    fake_code4 = np.array(fake_dic['fake_code4'])\n",
    "    if not np.all(fake_code4[:,vc]):\n",
    "        print(vc, np.sum(fake_code4[:,vc]==False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9849486566324378,0.3184713375796178,0.19083969465648856\n",
      "0.9762878168438267,0.4790419161676647,0.31496062992125984\n",
      "0.9782559964133603,0.21138211382113822,0.11818181818181818\n",
      "0.9675583380762663,0.7046632124352332,0.544\n",
      "0.9726166328600405,0.6785714285714285,0.5135135135135135\n",
      "0.9783338419285933,0.5847953216374269,0.4166666666666667\n",
      "0.985118560915781,0.06185567010309278,0.031914893617021274\n",
      "0.9455128205128206,0.4069767441860465,0.26515151515151514\n",
      "0.9438775510204083,0.794392523364486,0.6640625\n",
      "0.9708613512648094,0.48,0.3181818181818182\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import json\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def knn_cls_on_train(K, mat_dis, label):\n",
    "    np.fill_diagonal(mat_dis, 9999)\n",
    "    N = mat_dis.shape[0]\n",
    "    rst = np.zeros(N)\n",
    "    for nn in range(N):\n",
    "        nn_idx = np.argsort(mat_dis[nn])[0:K]\n",
    "        rst[nn] = np.rint(np.sum(label[nn_idx])/K)\n",
    "        \n",
    "    return rst\n",
    "\n",
    "\n",
    "file_path = '/export/home/qliu24/VC_adv_data/'\n",
    "for vc in range(0,10):\n",
    "    fake_dic = json.load(open(file_path+ 'vc' + str(vc) + 'fake', 'r'))\n",
    "    real_dic = json.load(open(file_path+ 'vc' + str(vc) + 'real', 'r'))\n",
    "\n",
    "    fake_code4 = np.array(fake_dic['fake_code4'])\n",
    "    fake_code4 = np.delete(fake_code4, (vc, ), axis=0)\n",
    "    real_code4 = np.array(real_dic['real_code4'])\n",
    "    \n",
    "    msk = np.concatenate([fake_code4[:,vc], real_code4[:,vc]], axis=0)\n",
    "    \n",
    "    # fake_code4[vc,vc] = False\n",
    "    # fake_code3 = np.array(fake_dic['fake_code3'])[fake_code4[:,vc]]\n",
    "\n",
    "    # real_code4 = np.array(real_dic['real_code4'])\n",
    "    # real_code3 = np.array(real_dic['real_code3'])[real_code4[:,vc]]\n",
    "\n",
    "    fake_code3 = np.array(fake_dic['fake_code3'])\n",
    "    real_code3 = np.array(real_dic['real_code3'])\n",
    "    fake_code3 = np.delete(fake_code3, (vc, ), axis=0)\n",
    "    concat = np.concatenate((fake_code3, real_code3), axis=0)\n",
    "    \n",
    "    N = concat.shape[0]\n",
    "    N_f = fake_code3.shape[0]\n",
    "    N_r = real_code3.shape[0]\n",
    "    \n",
    "    label1 = np.concatenate((np.zeros((N_f, )), np.ones((N_r, ))), axis=0)\n",
    "    label2 = np.concatenate((np.ones((N_f, )), np.zeros((N_r, ))), axis=0)\n",
    "    \n",
    "\n",
    "    with open(file_path + 'simmat_vc{0}.pickle'.format(vc),'rb') as fh:\n",
    "        mat_dis1, mat_dis2 = pickle.load(fh)\n",
    "\n",
    "    mat_full = mat_dis2 + mat_dis2.T - np.ones((N,N))\n",
    "    np.fill_diagonal(mat_full, 0)\n",
    "    \n",
    "    label1 = label1[msk]\n",
    "    label2 = label2[msk]\n",
    "    mat_full = mat_full[msk][:,msk]\n",
    "    N_f = np.sum(fake_code4[:,vc])\n",
    "    \n",
    "    predict1 = knn_cls_on_train(5, mat_full, label1)\n",
    "    predict2 = knn_cls_on_train(5, mat_full, label2)\n",
    "    print(\"{0},{1},{2}\".format(f1_score(label1, predict1), f1_score(label2, predict2), np.sum(label1[0:N_f] == predict1[0:N_f])/N_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845869297163995,0.7549019607843137,0.6416666666666667\n",
      "0.9836065573770493,0.10714285714285714,0.06382978723404255\n",
      "0.9469026548672566,0.5932203389830509,0.5303030303030303\n",
      "0.9774236387782204,0.9306122448979591,0.890625\n",
      "0.9824104234527687,0.763157894736842,0.6590909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "for vc in range(5,10):\n",
    "    # print(vc)\n",
    "    fake_dic = json.load(open(file_path+ 'vc' + str(vc) + 'fake', 'r'))\n",
    "    real_dic = json.load(open(file_path+ 'vc' + str(vc) + 'real', 'r'))\n",
    "    \n",
    "    fake_code4 = np.array(fake_dic['fake_code4'])\n",
    "    fake_code4 = np.delete(fake_code4, (vc, ), axis=0)\n",
    "    real_code4 = np.array(real_dic['real_code4'])\n",
    "    \n",
    "    msk = np.concatenate([fake_code4[:,vc], real_code4[:,vc]], axis=0)\n",
    "    \n",
    "    fake_code3 = np.array(fake_dic['fake_code3'])\n",
    "    real_code3 = np.array(real_dic['real_code3'])\n",
    "    fake_code3 = np.delete(fake_code3, (vc, ), axis=0)\n",
    "    concat = np.concatenate((fake_code3, real_code3), axis=0)\n",
    "    \n",
    "    N = concat.shape[0]\n",
    "    N_f = fake_code3.shape[0]\n",
    "    N_r = real_code3.shape[0]\n",
    "    \n",
    "    label1 = np.concatenate((np.zeros((N_f, )), np.ones((N_r, ))), axis=0)\n",
    "    label2 = np.concatenate((np.ones((N_f, )), np.zeros((N_r, ))), axis=0)\n",
    "    \n",
    "    with open(file_path + 'simmat_vc{0}.pickle'.format(vc),'rb') as fh:\n",
    "        mat_dis1, mat_dis2 = pickle.load(fh)\n",
    "\n",
    "    mat_full = mat_dis1 + mat_dis1.T - np.ones((N,N))\n",
    "    np.fill_diagonal(mat_full, 0)\n",
    "    \n",
    "    label1 = label1[msk]\n",
    "    label2 = label2[msk]\n",
    "    mat_full = mat_full[msk][:,msk]\n",
    "    N_f = np.sum(fake_code4[:,vc])\n",
    "    \n",
    "    model = TSNE(metric=\"precomputed\")\n",
    "    tsne_v = model.fit_transform(mat_full)\n",
    "    mat_dis = cdist(tsne_v, tsne_v)\n",
    "\n",
    "    predict1 = knn_cls_on_train(5, mat_dis, label1)\n",
    "    predict2 = knn_cls_on_train(5, mat_dis, label2)\n",
    "    print(\"{0},{1},{2}\".format(f1_score(label1, predict1), f1_score(label2, predict2), np.sum(label1[0:N_f] == predict1[0:N_f])/N_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# double check with Huiyu's Euclidean distance result\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "vc = 0\n",
    "fake_dic = json.load(open(file_path+ 'vc' + str(vc) + 'fake', 'r'))\n",
    "real_dic = json.load(open(file_path+ 'vc' + str(vc) + 'real', 'r'))\n",
    "\n",
    "fake_code3 = np.array(fake_dic['fake_code3'])\n",
    "real_code3 = np.array(real_dic['real_code3'])\n",
    "fake_code3 = np.delete(fake_code3, (vc, ), axis=0)\n",
    "concat = np.concatenate((fake_code3, real_code3), axis=0)\n",
    "label1 = np.concatenate((np.zeros((fake_code3.shape[0], )), np.ones((real_code3.shape[0], ))), axis=0)\n",
    "label2 = np.concatenate((np.ones((fake_code3.shape[0], )), np.zeros((real_code3.shape[0], ))), axis=0)\n",
    "\n",
    "N = concat.shape[0]\n",
    "print(N)\n",
    "mat_dis = cdist(concat.reshape(N,-1), concat.reshape(N,-1))\n",
    "print(mat_dis.shape)\n",
    "\n",
    "predict1 = knn_cls_on_train(5, mat_dis, label1)\n",
    "predict2 = knn_cls_on_train(5, mat_dis, label2)\n",
    "print(f1_score(label1, predict1), f1_score(label2, predict2))\n",
    "print(np.sum(label1[0:N_f] == predict1[0:N_f])/N_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094304388422035,0.3071428571428571,0.9847328244274809\n",
      "0.9054878048780488,0.4424460431654676,0.968503937007874\n",
      "0.9104514841606386,0.3756521739130435,0.9818181818181818\n",
      "0.9081567116249197,0.6361323155216285,1.0\n",
      "0.9233351986569669,0.6118980169971671,0.972972972972973\n",
      "0.9100169779286927,0.4731610337972167,0.9916666666666667\n",
      "0.9231868524473027,0.2996742671009772,0.9787234042553191\n",
      "0.9073170731707316,0.6237623762376238,0.9545454545454546\n",
      "0.9106881405563689,0.8063492063492065,0.9921875\n",
      "0.9105806911293196,0.48879837067209775,0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# check whether we can do KNN without fake samples (define a distance to distinguish real and fake)\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import json\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def knn_cls_no_neg(K, mat_dis, N_f, N_r, real_label):\n",
    "    N = mat_dis.shape[0]\n",
    "    assert(N==N_r+N_f)\n",
    "    np.fill_diagonal(mat_dis, 9999)\n",
    "    real_dis_ls = np.array([])\n",
    "    real_mat = mat_dis[N_f:N, N_f:N]\n",
    "    for nr in range(N_r):\n",
    "        idx_sort = np.argsort(real_mat[nr])[0:5]\n",
    "        real_dis_ls = np.append(real_dis_ls, real_mat[nr, idx_sort])\n",
    "        \n",
    "    thrh = np.mean(real_dis_ls) + np.std(real_dis_ls)\n",
    "    \n",
    "    rst = np.zeros(N)\n",
    "    mat_dis_obs = mat_dis[:, N_f:N]\n",
    "    for nn in range(N):\n",
    "        nn_idx = np.argsort(mat_dis_obs[nn])[0:K]\n",
    "        if np.sum(mat_dis_obs[nn, nn_idx]<thrh)/K < 0.5:\n",
    "            rst[nn] = 1-real_label\n",
    "        else:\n",
    "            rst[nn] = real_label\n",
    "        \n",
    "    return rst\n",
    "\n",
    "\n",
    "file_path = '/export/home/qliu24/VC_adv_data/'\n",
    "for vc in range(0,10):\n",
    "    fake_dic = json.load(open(file_path+ 'vc' + str(vc) + 'fake', 'r'))\n",
    "    real_dic = json.load(open(file_path+ 'vc' + str(vc) + 'real', 'r'))\n",
    "\n",
    "    fake_code4 = np.array(fake_dic['fake_code4'])\n",
    "    fake_code4 = np.delete(fake_code4, (vc, ), axis=0)\n",
    "    real_code4 = np.array(real_dic['real_code4'])\n",
    "    \n",
    "    msk = np.concatenate([fake_code4[:,vc], real_code4[:,vc]], axis=0)\n",
    "    \n",
    "    # fake_code4[vc,vc] = False\n",
    "    # fake_code3 = np.array(fake_dic['fake_code3'])[fake_code4[:,vc]]\n",
    "\n",
    "    # real_code4 = np.array(real_dic['real_code4'])\n",
    "    # real_code3 = np.array(real_dic['real_code3'])[real_code4[:,vc]]\n",
    "\n",
    "    fake_code3 = np.array(fake_dic['fake_code3'])\n",
    "    fake_code3 = np.delete(fake_code3, (vc, ), axis=0)\n",
    "    real_code3 = np.array(real_dic['real_code3'])\n",
    "    \n",
    "    concat = np.concatenate((fake_code3, real_code3), axis=0)\n",
    "    \n",
    "    N = concat.shape[0]\n",
    "    N_f = fake_code3.shape[0]\n",
    "    N_r = real_code3.shape[0]\n",
    "    \n",
    "    label1 = np.concatenate((np.zeros((N_f, )), np.ones((N_r, ))), axis=0)\n",
    "    label2 = np.concatenate((np.ones((N_f, )), np.zeros((N_r, ))), axis=0)\n",
    "    \n",
    "\n",
    "    with open(file_path + 'simmat_vc{0}.pickle'.format(vc),'rb') as fh:\n",
    "        mat_dis1, mat_dis2 = pickle.load(fh)\n",
    "\n",
    "    mat_full = mat_dis2 + mat_dis2.T - np.ones((N,N))\n",
    "    np.fill_diagonal(mat_full, 0)\n",
    "    \n",
    "    label1 = label1[msk]\n",
    "    label2 = label2[msk]\n",
    "    mat_full = mat_full[msk][:,msk]\n",
    "    N_r = np.sum(real_code4[:,vc])\n",
    "    N_f = np.sum(fake_code4[:,vc])\n",
    "    N = mat_full.shape[0]\n",
    "    try:\n",
    "        assert(N==N_r+N_f)\n",
    "    except:\n",
    "        print(N_f, N_r, N)\n",
    "    \n",
    "    kk=5\n",
    "    \n",
    "    '''\n",
    "    np.fill_diagonal(mat_full, 9999)\n",
    "    \n",
    "    real_dis_ls = np.array([])\n",
    "    real_mat = mat_full[N_f:N, N_f:N]\n",
    "    for nr in range(N_r):\n",
    "        idx_sort = np.argsort(real_mat[nr])[0:5]\n",
    "        real_dis_ls = np.append(real_dis_ls, real_mat[nr, idx_sort])\n",
    "        \n",
    "    fake_dis_ls = np.array([])\n",
    "    fake_mat = mat_full[0:N_f, N_f:N]\n",
    "    for nf in range(N_f):\n",
    "        idx_sort = np.argsort(fake_mat[nf])[0:5]\n",
    "        fake_dis_ls = np.append(fake_dis_ls, fake_mat[nf, idx_sort])\n",
    "        \n",
    "    print(np.mean(real_dis_ls), np.std(real_dis_ls), np.mean(fake_dis_ls), np.std(fake_dis_ls))\n",
    "    '''\n",
    "    \n",
    "    predict1 = knn_cls_no_neg(kk, mat_full, N_f, N_r, 1)\n",
    "    predict2 = knn_cls_no_neg(kk, mat_full, N_f, N_r, 0)\n",
    "    print(\"{0},{1},{2}\".format(f1_score(label1, predict1), f1_score(label2, predict2), np.sum(label1[0:N_f] == predict1[0:N_f])/N_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207090"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(real_code3[:,vc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/home/qliu24/qing_voting_139/qing_clustering\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
